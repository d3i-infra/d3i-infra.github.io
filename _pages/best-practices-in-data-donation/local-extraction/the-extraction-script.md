---
layout: single
title:  The extraction script
permalink: /best-practices-in-data-donation/local-extraction/the-extraction-script
toc: false
sidebar:
  nav: "best-practices-in-data-donation"
---

The extraction script starts with reading in the DDP and selecting the files that will be processed. The script should be built so that different file types can be imported. DDPs can consist of a wide variety of files, such as .txt-files, .JSON-files, .HTML-files, and .jpg-files. The file type of the target data can differ over DDPs. For example, when requesting a Facebook DDP, a choice can be made between .JSON-files and .HTML-files. Therefore, the script should ideally be able to handle different file types. Although the aim is to build a robust script regarding file types, it should be specified how the script deals with unforeseen file types or incorrect files. These specifications are called exception handling. Good practices for exception handling are including logs, alerting participants, and making sure the exceptions do not result in errors aborting the entire script. Although discussed here for reading in DDPs, exception handling should be considered for all script elements.

Once the DDP is read in correctly, the extraction script continues with extracting and processing the targeted data. The level of processing differs per data donation study, and can range from no processing at all to advanced algorithms that process the data. For example, in the social media inferred interest study (RQ 2), no processing of the targeted data occurred, and the extracted data formed the direct output data. Contrarily, in the GSLH study (RQ 1) and the WhatsApp study (RQ 3), targeted data were processed to summary statistics as the output. An example of processing with an algorithm could be a study where a personâ€™s mood is inferred from pictures on social media, where solely a mood state is presented as the output.

In data donation studies where the processing makes use of algorithms or prediction models, performance of these algorithms should be taken into account. Algorithms and prediction models are seldom perfect and error can occur in their processing of the targeted data. Although this error might be hard to account for, thorough evaluation of used algorithms should take place to minimize the influence of their potential inaccuracy.

While the script is extracting and processing the targeted data, feedback should be provided to participants. Extraction and processing can take up high amounts of time when for example complex algorithms are used or when large amount of data need to be processed. When these times get higher than anticipated by participants, participants might quit the process, assuming that a problem was encountered. To prevent this from happening, it needs to be ensured that expectations about the extraction time are communicated clearly, either in instructions prior to extraction, or by feedback provided by the extraction script.

Potentially, local interaction between the participant and the script helps the researcher to extract the required data while preserving the privacy of the participants. In such a case, an interactive script element can be used. Interactive script elements are steps in the processing in which input of the participant is required. For example, in the WhatsApp data donation study (RQ 3), participants had to indicate their name from a list of all users present in the chat file. This way, distinction could be made between the data on the participant and data on other chat users. The names present in the chat were not saved to preserve privacy, but the indication of what data belonged to the participant grants information that could not be obtained without the input of the participant.

The final part of the extraction script summarizes the extracted data and transforms these to the output that is presented to the participant. The presentation differs based on the data extracted. The data can be clear and summarily, or can become a long, potentially obscure list. Optionally, it can be decided that the participant can edit or delete part of the output presented. For example, in the inferred interests study (RQ 2), participants could delete individual data points from the list of extracted interests. In the data donation studies we conducted so far, output presentation always had the form of tabular data. Potentially, other forms of output presentation could improve participant-experiences, such as visualizations with the aim of providing participants insights about themselves (Gomez Ortega et al., 2021; Li, 2021). It can be desirable to consult the IT expert to check if all ideas for the output presentation are feasible for the software used.